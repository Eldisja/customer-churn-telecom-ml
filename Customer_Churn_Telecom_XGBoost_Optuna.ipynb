{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LHGr10zDqkD7"
      },
      "outputs": [],
      "source": [
        "!pip install -q optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BpRQrX4poc_X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
        "import xgboost as xgb\n",
        "import optuna\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St8QsR1gorpa"
      },
      "outputs": [],
      "source": [
        "# Load the dataset  \n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Project_CV/Telco-Customer-Churn.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFt3OZ_Aovqx"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns  \n",
        "df.drop(\"customerID\", axis=1, inplace=True)\n",
        "\n",
        "# Clean data in the TotalCharges column  \n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Encode the target column  \n",
        "df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})\n",
        "\n",
        "# Encode categorical features  \n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-8rkMhYoxgu"
      },
      "outputs": [],
      "source": [
        "# Split the data  \n",
        "X = df.drop('Churn', axis=1).reset_index(drop=True)\n",
        "y = df['Churn'].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpDWN3mmqIFy"
      },
      "outputs": [],
      "source": [
        "# Perform Stratified K-Fold  \n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVvXsQ5zo4EN"
      },
      "outputs": [],
      "source": [
        "# Optuna hyperparameter tuning function  \n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"eval_metric\": [\"logloss\", \"error\"],\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
        "    }\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Skip if data does not contain both classes \n",
        "        if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n",
        "            print(f\"Skipping fold {fold+1}: only one class in y_train or y_test\")\n",
        "            continue\n",
        "\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        evals_result = model.evals_result()\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        scores.append(acc)\n",
        "\n",
        "        print(f\"Fold {fold+1} - Train logloss: {evals_result['validation_0']['logloss'][-1]:.4f}, \"\n",
        "              f\"Train error: {evals_result['validation_0']['error'][-1]:.4f}, \"\n",
        "              f\"Val logloss: {evals_result['validation_1']['logloss'][-1]:.4f}, \"\n",
        "              f\"Val error: {evals_result['validation_1']['error'][-1]:.4f}\")\n",
        "\n",
        "    return np.mean(scores) if scores else 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU0k6F_-o7jN",
        "outputId": "b4bc830d-2749-45a2-d31e-780ba5cd0ac6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:26:48,971] A new study created in memory with name: no-name-395d1d7d-c902-4f15-a3f5-aaea6f45baf6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 - Train logloss: 0.4109, Train error: 0.1952, Val logloss: 0.4193, Val error: 0.1912\n",
            "Fold 2 - Train logloss: 0.4123, Train error: 0.1934, Val logloss: 0.4151, Val error: 0.1969\n",
            "Fold 3 - Train logloss: 0.4104, Train error: 0.1927, Val logloss: 0.4259, Val error: 0.2148\n",
            "Fold 4 - Train logloss: 0.4103, Train error: 0.1939, Val logloss: 0.4204, Val error: 0.1956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:26:53,964] Trial 0 finished with value: 0.8011931806118767 and parameters: {'max_depth': 3, 'learning_rate': 0.021555907680362137, 'n_estimators': 131, 'subsample': 0.8456422217582689, 'colsample_bytree': 0.6300713599672738}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.4099, Train error: 0.1973, Val logloss: 0.4252, Val error: 0.1956\n",
            "Fold 1 - Train logloss: 0.2297, Train error: 0.0884, Val logloss: 0.4688, Val error: 0.2082\n",
            "Fold 2 - Train logloss: 0.2258, Train error: 0.0875, Val logloss: 0.4813, Val error: 0.2175\n",
            "Fold 3 - Train logloss: 0.2264, Train error: 0.0859, Val logloss: 0.4785, Val error: 0.2297\n",
            "Fold 4 - Train logloss: 0.2263, Train error: 0.0864, Val logloss: 0.4801, Val error: 0.2176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:26:56,733] Trial 1 finished with value: 0.7819951249644888 and parameters: {'max_depth': 4, 'learning_rate': 0.2634773093470411, 'n_estimators': 266, 'subsample': 0.7019316820890591, 'colsample_bytree': 0.9706429566008548}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.2278, Train error: 0.0903, Val logloss: 0.4976, Val error: 0.2169\n",
            "Fold 1 - Train logloss: 0.0775, Train error: 0.0066, Val logloss: 0.5460, Val error: 0.2118\n",
            "Fold 2 - Train logloss: 0.0786, Train error: 0.0068, Val logloss: 0.5688, Val error: 0.2232\n",
            "Fold 3 - Train logloss: 0.0780, Train error: 0.0069, Val logloss: 0.5565, Val error: 0.2440\n",
            "Fold 4 - Train logloss: 0.0761, Train error: 0.0060, Val logloss: 0.5761, Val error: 0.2319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:03,891] Trial 2 finished with value: 0.7747418162186426 and parameters: {'max_depth': 10, 'learning_rate': 0.1412462925871286, 'n_estimators': 268, 'subsample': 0.6409528116170244, 'colsample_bytree': 0.563549646859764}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.0790, Train error: 0.0073, Val logloss: 0.5659, Val error: 0.2155\n",
            "Fold 1 - Train logloss: 0.1032, Train error: 0.0105, Val logloss: 0.4964, Val error: 0.2104\n",
            "Fold 2 - Train logloss: 0.1057, Train error: 0.0101, Val logloss: 0.5062, Val error: 0.2154\n",
            "Fold 3 - Train logloss: 0.1008, Train error: 0.0096, Val logloss: 0.5060, Val error: 0.2219\n",
            "Fold 4 - Train logloss: 0.1046, Train error: 0.0089, Val logloss: 0.5117, Val error: 0.2091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:06,371] Trial 3 finished with value: 0.7856935602418714 and parameters: {'max_depth': 10, 'learning_rate': 0.17980501298615562, 'n_estimators': 147, 'subsample': 0.9805434607042596, 'colsample_bytree': 0.5748918957719726}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.0999, Train error: 0.0105, Val logloss: 0.5010, Val error: 0.2148\n",
            "Fold 1 - Train logloss: 0.3074, Train error: 0.1344, Val logloss: 0.4329, Val error: 0.1947\n",
            "Fold 2 - Train logloss: 0.3110, Train error: 0.1394, Val logloss: 0.4338, Val error: 0.2139\n",
            "Fold 3 - Train logloss: 0.3070, Train error: 0.1351, Val logloss: 0.4342, Val error: 0.2198\n",
            "Fold 4 - Train logloss: 0.3064, Train error: 0.1378, Val logloss: 0.4459, Val error: 0.2127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:09,123] Trial 4 finished with value: 0.790527549207832 and parameters: {'max_depth': 3, 'learning_rate': 0.22502772025626258, 'n_estimators': 286, 'subsample': 0.9622329004184598, 'colsample_bytree': 0.8981415034549366}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3045, Train error: 0.1338, Val logloss: 0.4470, Val error: 0.2063\n",
            "Fold 1 - Train logloss: 0.3305, Train error: 0.1518, Val logloss: 0.4334, Val error: 0.2018\n",
            "Fold 2 - Train logloss: 0.3314, Train error: 0.1476, Val logloss: 0.4344, Val error: 0.2104\n",
            "Fold 3 - Train logloss: 0.3301, Train error: 0.1523, Val logloss: 0.4371, Val error: 0.2183\n",
            "Fold 4 - Train logloss: 0.3285, Train error: 0.1516, Val logloss: 0.4360, Val error: 0.1999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:10,984] Trial 5 finished with value: 0.7939419949632047 and parameters: {'max_depth': 3, 'learning_rate': 0.27749145552271326, 'n_estimators': 189, 'subsample': 0.8266776892704109, 'colsample_bytree': 0.5041553919440538}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3268, Train error: 0.1506, Val logloss: 0.4440, Val error: 0.1999\n",
            "Fold 1 - Train logloss: 0.3307, Train error: 0.1552, Val logloss: 0.4248, Val error: 0.1983\n",
            "Fold 2 - Train logloss: 0.3290, Train error: 0.1492, Val logloss: 0.4156, Val error: 0.1990\n",
            "Fold 3 - Train logloss: 0.3292, Train error: 0.1527, Val logloss: 0.4216, Val error: 0.2063\n",
            "Fold 4 - Train logloss: 0.3283, Train error: 0.1504, Val logloss: 0.4281, Val error: 0.2027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:13,242] Trial 6 finished with value: 0.7984917922074246 and parameters: {'max_depth': 4, 'learning_rate': 0.15522469991767027, 'n_estimators': 123, 'subsample': 0.965576927552193, 'colsample_bytree': 0.7484662176114347}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3269, Train error: 0.1497, Val logloss: 0.4324, Val error: 0.2013\n",
            "Fold 1 - Train logloss: 0.1097, Train error: 0.0148, Val logloss: 0.5344, Val error: 0.2132\n",
            "Fold 2 - Train logloss: 0.1083, Train error: 0.0133, Val logloss: 0.5537, Val error: 0.2338\n",
            "Fold 3 - Train logloss: 0.1049, Train error: 0.0133, Val logloss: 0.5563, Val error: 0.2482\n",
            "Fold 4 - Train logloss: 0.1083, Train error: 0.0130, Val logloss: 0.5526, Val error: 0.2176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:18,137] Trial 7 finished with value: 0.7724675747456579 and parameters: {'max_depth': 7, 'learning_rate': 0.23963186619719135, 'n_estimators': 220, 'subsample': 0.7519122036645045, 'colsample_bytree': 0.5218258293521273}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.1111, Train error: 0.0146, Val logloss: 0.5621, Val error: 0.2248\n",
            "Fold 1 - Train logloss: 0.3594, Train error: 0.1659, Val logloss: 0.4197, Val error: 0.1947\n",
            "Fold 2 - Train logloss: 0.3619, Train error: 0.1682, Val logloss: 0.4109, Val error: 0.2004\n",
            "Fold 3 - Train logloss: 0.3591, Train error: 0.1689, Val logloss: 0.4198, Val error: 0.2148\n",
            "Fold 4 - Train logloss: 0.3592, Train error: 0.1673, Val logloss: 0.4212, Val error: 0.2034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:19,622] Trial 8 finished with value: 0.7982069938864911 and parameters: {'max_depth': 3, 'learning_rate': 0.1593175951817572, 'n_estimators': 142, 'subsample': 0.911613955696476, 'colsample_bytree': 0.6334213777409948}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3589, Train error: 0.1697, Val logloss: 0.4233, Val error: 0.1956\n",
            "Fold 1 - Train logloss: 0.0879, Train error: 0.0073, Val logloss: 0.5199, Val error: 0.2125\n",
            "Fold 2 - Train logloss: 0.0825, Train error: 0.0059, Val logloss: 0.5544, Val error: 0.2239\n",
            "Fold 3 - Train logloss: 0.0842, Train error: 0.0071, Val logloss: 0.5449, Val error: 0.2368\n",
            "Fold 4 - Train logloss: 0.0836, Train error: 0.0069, Val logloss: 0.5563, Val error: 0.2240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:22,588] Trial 9 finished with value: 0.7765912360570649 and parameters: {'max_depth': 8, 'learning_rate': 0.24455662459148367, 'n_estimators': 209, 'subsample': 0.9972337962011428, 'colsample_bytree': 0.8800119906711603}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.0755, Train error: 0.0069, Val logloss: 0.5844, Val error: 0.2198\n",
            "Fold 1 - Train logloss: 0.4001, Train error: 0.1820, Val logloss: 0.4299, Val error: 0.1997\n",
            "Fold 2 - Train logloss: 0.4005, Train error: 0.1801, Val logloss: 0.4245, Val error: 0.1919\n",
            "Fold 3 - Train logloss: 0.3986, Train error: 0.1802, Val logloss: 0.4334, Val error: 0.2141\n",
            "Fold 4 - Train logloss: 0.3993, Train error: 0.1817, Val logloss: 0.4309, Val error: 0.2020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:24,137] Trial 10 finished with value: 0.8006246960685296 and parameters: {'max_depth': 6, 'learning_rate': 0.014997325029933718, 'n_estimators': 103, 'subsample': 0.5081292492168745, 'colsample_bytree': 0.7136011977617476}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3994, Train error: 0.1831, Val logloss: 0.4315, Val error: 0.1892\n",
            "Fold 1 - Train logloss: 0.4072, Train error: 0.1858, Val logloss: 0.4344, Val error: 0.2047\n",
            "Fold 2 - Train logloss: 0.4081, Train error: 0.1836, Val logloss: 0.4303, Val error: 0.1983\n",
            "Fold 3 - Train logloss: 0.4061, Train error: 0.1847, Val logloss: 0.4378, Val error: 0.2169\n",
            "Fold 4 - Train logloss: 0.4070, Train error: 0.1863, Val logloss: 0.4365, Val error: 0.2070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:25,707] Trial 11 finished with value: 0.7965011358569882 and parameters: {'max_depth': 6, 'learning_rate': 0.013616452615775126, 'n_estimators': 100, 'subsample': 0.5909334213791007, 'colsample_bytree': 0.7022550813833652}. Best is trial 0 with value: 0.8011931806118767.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.4065, Train error: 0.1841, Val logloss: 0.4365, Val error: 0.1906\n",
            "Fold 1 - Train logloss: 0.3896, Train error: 0.1813, Val logloss: 0.4181, Val error: 0.1933\n",
            "Fold 2 - Train logloss: 0.3916, Train error: 0.1813, Val logloss: 0.4114, Val error: 0.1919\n",
            "Fold 3 - Train logloss: 0.3902, Train error: 0.1797, Val logloss: 0.4204, Val error: 0.2112\n",
            "Fold 4 - Train logloss: 0.3892, Train error: 0.1801, Val logloss: 0.4192, Val error: 0.2006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:30,580] Trial 12 finished with value: 0.8040377264257861 and parameters: {'max_depth': 5, 'learning_rate': 0.01429078185192112, 'n_estimators': 169, 'subsample': 0.5294813628002644, 'colsample_bytree': 0.6656412526276898}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3896, Train error: 0.1811, Val logloss: 0.4202, Val error: 0.1828\n",
            "Fold 1 - Train logloss: 0.3193, Train error: 0.1483, Val logloss: 0.4234, Val error: 0.1969\n",
            "Fold 2 - Train logloss: 0.3193, Train error: 0.1433, Val logloss: 0.4143, Val error: 0.1976\n",
            "Fold 3 - Train logloss: 0.3161, Train error: 0.1443, Val logloss: 0.4225, Val error: 0.2162\n",
            "Fold 4 - Train logloss: 0.3194, Train error: 0.1418, Val logloss: 0.4253, Val error: 0.2013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:32,647] Trial 13 finished with value: 0.7996293678933113 and parameters: {'max_depth': 5, 'learning_rate': 0.06897033673013939, 'n_estimators': 173, 'subsample': 0.8304837250773021, 'colsample_bytree': 0.6366242995366338}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3172, Train error: 0.1440, Val logloss: 0.4255, Val error: 0.1899\n",
            "Fold 1 - Train logloss: 0.3194, Train error: 0.1481, Val logloss: 0.4194, Val error: 0.1933\n",
            "Fold 2 - Train logloss: 0.3215, Train error: 0.1444, Val logloss: 0.4171, Val error: 0.2075\n",
            "Fold 3 - Train logloss: 0.3165, Train error: 0.1426, Val logloss: 0.4220, Val error: 0.2141\n",
            "Fold 4 - Train logloss: 0.3178, Train error: 0.1426, Val logloss: 0.4324, Val error: 0.2027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:34,717] Trial 14 finished with value: 0.7989190402387575 and parameters: {'max_depth': 5, 'learning_rate': 0.0701464353786458, 'n_estimators': 167, 'subsample': 0.5095496068058942, 'colsample_bytree': 0.8137388972213953}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3167, Train error: 0.1418, Val logloss: 0.4302, Val error: 0.1878\n",
            "Fold 1 - Train logloss: 0.3247, Train error: 0.1492, Val logloss: 0.4214, Val error: 0.1940\n",
            "Fold 2 - Train logloss: 0.3256, Train error: 0.1468, Val logloss: 0.4116, Val error: 0.2018\n",
            "Fold 3 - Train logloss: 0.3226, Train error: 0.1482, Val logloss: 0.4197, Val error: 0.2141\n",
            "Fold 4 - Train logloss: 0.3271, Train error: 0.1461, Val logloss: 0.4215, Val error: 0.2020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:36,505] Trial 15 finished with value: 0.8001985601357164 and parameters: {'max_depth': 5, 'learning_rate': 0.07479569962851078, 'n_estimators': 142, 'subsample': 0.8295180972711221, 'colsample_bytree': 0.6505410605064608}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3228, Train error: 0.1470, Val logloss: 0.4252, Val error: 0.1871\n",
            "Fold 1 - Train logloss: 0.3117, Train error: 0.1385, Val logloss: 0.4275, Val error: 0.1940\n",
            "Fold 2 - Train logloss: 0.3135, Train error: 0.1381, Val logloss: 0.4250, Val error: 0.2011\n",
            "Fold 3 - Train logloss: 0.3123, Train error: 0.1420, Val logloss: 0.4288, Val error: 0.2127\n",
            "Fold 4 - Train logloss: 0.3115, Train error: 0.1378, Val logloss: 0.4337, Val error: 0.2034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:39,059] Trial 16 finished with value: 0.7972112613118112 and parameters: {'max_depth': 4, 'learning_rate': 0.10557488830073393, 'n_estimators': 232, 'subsample': 0.7587298963191396, 'colsample_bytree': 0.8044359335331871}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3092, Train error: 0.1381, Val logloss: 0.4358, Val error: 0.2027\n",
            "Fold 1 - Train logloss: 0.2649, Train error: 0.1015, Val logloss: 0.4257, Val error: 0.1898\n",
            "Fold 2 - Train logloss: 0.2657, Train error: 0.1020, Val logloss: 0.4193, Val error: 0.1990\n",
            "Fold 3 - Train logloss: 0.2632, Train error: 0.1040, Val logloss: 0.4302, Val error: 0.2183\n",
            "Fold 4 - Train logloss: 0.2648, Train error: 0.1050, Val logloss: 0.4302, Val error: 0.2013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:48,350] Trial 17 finished with value: 0.7992018165623821 and parameters: {'max_depth': 8, 'learning_rate': 0.04084467222335582, 'n_estimators': 170, 'subsample': 0.6028478438693134, 'colsample_bytree': 0.603511577395968}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.2669, Train error: 0.0992, Val logloss: 0.4281, Val error: 0.1956\n",
            "Fold 1 - Train logloss: 0.3448, Train error: 0.1593, Val logloss: 0.4200, Val error: 0.1997\n",
            "Fold 2 - Train logloss: 0.3460, Train error: 0.1579, Val logloss: 0.4076, Val error: 0.1898\n",
            "Fold 3 - Train logloss: 0.3479, Train error: 0.1605, Val logloss: 0.4189, Val error: 0.2127\n",
            "Fold 4 - Train logloss: 0.3467, Train error: 0.1594, Val logloss: 0.4210, Val error: 0.2034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:51,953] Trial 18 finished with value: 0.8003398977475961 and parameters: {'max_depth': 4, 'learning_rate': 0.11031735048487372, 'n_estimators': 124, 'subsample': 0.8801976719135067, 'colsample_bytree': 0.672209037274716}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3437, Train error: 0.1625, Val logloss: 0.4256, Val error: 0.1927\n",
            "Fold 1 - Train logloss: 0.2534, Train error: 0.0992, Val logloss: 0.4289, Val error: 0.1962\n",
            "Fold 2 - Train logloss: 0.2542, Train error: 0.1006, Val logloss: 0.4237, Val error: 0.1955\n",
            "Fold 3 - Train logloss: 0.2527, Train error: 0.0960, Val logloss: 0.4325, Val error: 0.2183\n",
            "Fold 4 - Train logloss: 0.2550, Train error: 0.0983, Val logloss: 0.4319, Val error: 0.2041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:27:59,932] Trial 19 finished with value: 0.7964995182591412 and parameters: {'max_depth': 7, 'learning_rate': 0.041075576738775474, 'n_estimators': 237, 'subsample': 0.6908010050243774, 'colsample_bytree': 0.8088578282837771}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.2527, Train error: 0.0956, Val logloss: 0.4344, Val error: 0.2034\n",
            "Fold 1 - Train logloss: 0.2269, Train error: 0.0789, Val logloss: 0.4484, Val error: 0.2033\n",
            "Fold 2 - Train logloss: 0.2214, Train error: 0.0777, Val logloss: 0.4605, Val error: 0.2068\n",
            "Fold 3 - Train logloss: 0.2250, Train error: 0.0812, Val logloss: 0.4668, Val error: 0.2304\n",
            "Fold 4 - Train logloss: 0.2234, Train error: 0.0773, Val logloss: 0.4762, Val error: 0.2205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:02,156] Trial 20 finished with value: 0.7868293161301803 and parameters: {'max_depth': 5, 'learning_rate': 0.19640641291642452, 'n_estimators': 190, 'subsample': 0.790727645883478, 'colsample_bytree': 0.7414715979140656}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.2230, Train error: 0.0805, Val logloss: 0.4739, Val error: 0.2048\n",
            "Fold 1 - Train logloss: 0.4130, Train error: 0.1900, Val logloss: 0.4377, Val error: 0.2018\n",
            "Fold 2 - Train logloss: 0.4133, Train error: 0.1904, Val logloss: 0.4335, Val error: 0.1990\n",
            "Fold 3 - Train logloss: 0.4118, Train error: 0.1856, Val logloss: 0.4413, Val error: 0.2240\n",
            "Fold 4 - Train logloss: 0.4123, Train error: 0.1886, Val logloss: 0.4386, Val error: 0.2063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:03,830] Trial 21 finished with value: 0.7956473474933805 and parameters: {'max_depth': 6, 'learning_rate': 0.01147606033011228, 'n_estimators': 111, 'subsample': 0.5098440842086431, 'colsample_bytree': 0.6901738302310266}. Best is trial 12 with value: 0.8040377264257861.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.4122, Train error: 0.1873, Val logloss: 0.4393, Val error: 0.1906\n",
            "Fold 1 - Train logloss: 0.3377, Train error: 0.1543, Val logloss: 0.4178, Val error: 0.1926\n",
            "Fold 2 - Train logloss: 0.3388, Train error: 0.1525, Val logloss: 0.4094, Val error: 0.2004\n",
            "Fold 3 - Train logloss: 0.3367, Train error: 0.1529, Val logloss: 0.4154, Val error: 0.2041\n",
            "Fold 4 - Train logloss: 0.3375, Train error: 0.1554, Val logloss: 0.4169, Val error: 0.1963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:11,676] Trial 22 finished with value: 0.80460782856698 and parameters: {'max_depth': 6, 'learning_rate': 0.03877299918289841, 'n_estimators': 127, 'subsample': 0.5527172291879321, 'colsample_bytree': 0.7226512598943868}. Best is trial 22 with value: 0.80460782856698.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3396, Train error: 0.1569, Val logloss: 0.4181, Val error: 0.1835\n",
            "Fold 1 - Train logloss: 0.2642, Train error: 0.1031, Val logloss: 0.4293, Val error: 0.1997\n",
            "Fold 2 - Train logloss: 0.2678, Train error: 0.1072, Val logloss: 0.4213, Val error: 0.2011\n",
            "Fold 3 - Train logloss: 0.2626, Train error: 0.1020, Val logloss: 0.4290, Val error: 0.2191\n",
            "Fold 4 - Train logloss: 0.2641, Train error: 0.1049, Val logloss: 0.4310, Val error: 0.2006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:14,200] Trial 23 finished with value: 0.7974965651320719 and parameters: {'max_depth': 8, 'learning_rate': 0.04603677298071491, 'n_estimators': 156, 'subsample': 0.5688058830636005, 'colsample_bytree': 0.6022931472535618}. Best is trial 22 with value: 0.80460782856698.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.2674, Train error: 0.1026, Val logloss: 0.4289, Val error: 0.1920\n",
            "Fold 1 - Train logloss: 0.2386, Train error: 0.0887, Val logloss: 0.4461, Val error: 0.2018\n",
            "Fold 2 - Train logloss: 0.2430, Train error: 0.0905, Val logloss: 0.4363, Val error: 0.2090\n",
            "Fold 3 - Train logloss: 0.2358, Train error: 0.0835, Val logloss: 0.4458, Val error: 0.2248\n",
            "Fold 4 - Train logloss: 0.2356, Train error: 0.0848, Val logloss: 0.4608, Val error: 0.2191\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:16,161] Trial 24 finished with value: 0.7859759321660342 and parameters: {'max_depth': 7, 'learning_rate': 0.1018744234066869, 'n_estimators': 126, 'subsample': 0.5578944351417335, 'colsample_bytree': 0.7545870543719699}. Best is trial 22 with value: 0.80460782856698.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.2373, Train error: 0.0835, Val logloss: 0.4520, Val error: 0.2155\n",
            "Fold 1 - Train logloss: 0.3292, Train error: 0.1497, Val logloss: 0.4184, Val error: 0.1969\n",
            "Fold 2 - Train logloss: 0.3314, Train error: 0.1481, Val logloss: 0.4095, Val error: 0.1969\n",
            "Fold 3 - Train logloss: 0.3294, Train error: 0.1520, Val logloss: 0.4159, Val error: 0.2034\n",
            "Fold 4 - Train logloss: 0.3285, Train error: 0.1506, Val logloss: 0.4203, Val error: 0.2034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:18,038] Trial 25 finished with value: 0.8013362369214686 and parameters: {'max_depth': 6, 'learning_rate': 0.04017487891630932, 'n_estimators': 133, 'subsample': 0.6642448422014993, 'colsample_bytree': 0.7742666427361024}. Best is trial 22 with value: 0.80460782856698.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3265, Train error: 0.1447, Val logloss: 0.4225, Val error: 0.1927\n",
            "Fold 1 - Train logloss: 0.2926, Train error: 0.1278, Val logloss: 0.4272, Val error: 0.1990\n",
            "Fold 2 - Train logloss: 0.2941, Train error: 0.1271, Val logloss: 0.4196, Val error: 0.2026\n",
            "Fold 3 - Train logloss: 0.2919, Train error: 0.1269, Val logloss: 0.4236, Val error: 0.2098\n",
            "Fold 4 - Train logloss: 0.2926, Train error: 0.1274, Val logloss: 0.4299, Val error: 0.2048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:20,218] Trial 26 finished with value: 0.7972121712106002 and parameters: {'max_depth': 6, 'learning_rate': 0.05813321463455496, 'n_estimators': 159, 'subsample': 0.6410928768661381, 'colsample_bytree': 0.8587895081464395}. Best is trial 22 with value: 0.80460782856698.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.2948, Train error: 0.1266, Val logloss: 0.4289, Val error: 0.1977\n",
            "Fold 1 - Train logloss: 0.1480, Train error: 0.0256, Val logloss: 0.4710, Val error: 0.2004\n",
            "Fold 2 - Train logloss: 0.1448, Train error: 0.0252, Val logloss: 0.4723, Val error: 0.2132\n",
            "Fold 3 - Train logloss: 0.1419, Train error: 0.0254, Val logloss: 0.4795, Val error: 0.2276\n",
            "Fold 4 - Train logloss: 0.1426, Train error: 0.0252, Val logloss: 0.4830, Val error: 0.2141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:26,145] Trial 27 finished with value: 0.7879678017148559 and parameters: {'max_depth': 9, 'learning_rate': 0.0907630925588746, 'n_estimators': 185, 'subsample': 0.6635143197603258, 'colsample_bytree': 0.7723080485717904}. Best is trial 22 with value: 0.80460782856698.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.1436, Train error: 0.0238, Val logloss: 0.4845, Val error: 0.2048\n",
            "Fold 1 - Train logloss: 0.2921, Train error: 0.1285, Val logloss: 0.4372, Val error: 0.2061\n",
            "Fold 2 - Train logloss: 0.2922, Train error: 0.1264, Val logloss: 0.4305, Val error: 0.2139\n",
            "Fold 3 - Train logloss: 0.2929, Train error: 0.1276, Val logloss: 0.4415, Val error: 0.2191\n",
            "Fold 4 - Train logloss: 0.2899, Train error: 0.1257, Val logloss: 0.4350, Val error: 0.2134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:28,305] Trial 28 finished with value: 0.789248939209662 and parameters: {'max_depth': 5, 'learning_rate': 0.13408322332582892, 'n_estimators': 140, 'subsample': 0.5446880237721701, 'colsample_bytree': 0.7247243247912222}. Best is trial 22 with value: 0.80460782856698.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.2926, Train error: 0.1290, Val logloss: 0.4458, Val error: 0.2013\n",
            "Fold 1 - Train logloss: 0.3109, Train error: 0.1339, Val logloss: 0.4208, Val error: 0.1983\n",
            "Fold 2 - Train logloss: 0.3147, Train error: 0.1388, Val logloss: 0.4102, Val error: 0.1947\n",
            "Fold 3 - Train logloss: 0.3121, Train error: 0.1369, Val logloss: 0.4200, Val error: 0.2091\n",
            "Fold 4 - Train logloss: 0.3105, Train error: 0.1392, Val logloss: 0.4219, Val error: 0.2020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 16:28:30,229] Trial 29 finished with value: 0.8014783833322717 and parameters: {'max_depth': 7, 'learning_rate': 0.038674670924613186, 'n_estimators': 118, 'subsample': 0.6081933836761709, 'colsample_bytree': 0.778918941641634}. Best is trial 22 with value: 0.80460782856698.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 - Train logloss: 0.3142, Train error: 0.1358, Val logloss: 0.4230, Val error: 0.1885\n"
          ]
        }
      ],
      "source": [
        "# Perform tuning with Optuna  \n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoaxOJCRsOC1",
        "outputId": "06f62a57-613b-4cdb-e70f-d9603c465239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best parameters found by Optuna:\n",
            "{'max_depth': 6, 'learning_rate': 0.03877299918289841, 'n_estimators': 127, 'subsample': 0.5527172291879321, 'colsample_bytree': 0.7226512598943868, 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error']}\n"
          ]
        }
      ],
      "source": [
        "# Save the final model with the best parameters \n",
        "best_params = study.best_params\n",
        "best_params.update({\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": [\"logloss\", \"error\"]\n",
        "})\n",
        "\n",
        "print(\"\\nBest parameters found by Optuna:\")\n",
        "print(best_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYmmntACsQAy",
        "outputId": "74d3885f-dcc5-4e09-eb6d-60c2d640220e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 - F1 Score: 0.7321, Accuracy: 0.8074, Precision: 0.7598\n",
            "Fold 2 - F1 Score: 0.7226, Accuracy: 0.7996, Precision: 0.7472\n",
            "Fold 3 - F1 Score: 0.7208, Accuracy: 0.7959, Precision: 0.7400\n",
            "Fold 4 - F1 Score: 0.7268, Accuracy: 0.8037, Precision: 0.7544\n",
            "Fold 5 - F1 Score: 0.7441, Accuracy: 0.8165, Precision: 0.7746\n",
            "\n",
            "Model terbaik disimpan dari fold 5 dengan F1 Score: 0.7441\n"
          ]
        }
      ],
      "source": [
        "# Re-evaluate the model  \n",
        "f1_scores, acc_scores, prec_scores = [], [], []\n",
        "models = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    if len(np.unique(y_train)) < 2 or len(np.unique(y_test)) < 2:\n",
        "        print(f\"Skipping final fold {fold+1}: only one class present.\")\n",
        "        continue\n",
        "\n",
        "    model = xgb.XGBClassifier(**best_params)\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    f1_scores.append(f1)\n",
        "    acc_scores.append(acc)\n",
        "    prec_scores.append(prec)\n",
        "    models.append(model)\n",
        "\n",
        "    print(f\"Fold {fold+1} - F1 Score: {f1:.4f}, Accuracy: {acc:.4f}, Precision: {prec:.4f}\")\n",
        "\n",
        "# Find the best model index based on F1-score  \n",
        "best_index = np.argmax(f1_scores)\n",
        "best_model = models[best_index]\n",
        "\n",
        "# Save the best model to file  \n",
        "joblib.dump(best_model, f\"/content/drive/MyDrive/Project_CV/xgb_model_best_fold{fold+1}.pkl\")\n",
        "print(f\"\\nModel terbaik disimpan dari fold {best_index + 1} dengan F1 Score: {f1_scores[best_index]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c7CY3W-sRQJ",
        "outputId": "e90db919-b5f9-42ae-a5e8-5f050ba409f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluasi Model per Fold ===\n",
            "   Fold  F1 Score (macro)  Accuracy (macro)  Precision (macro)\n",
            "0     1          0.732072          0.807392           0.759811\n",
            "1     2          0.722646          0.799574           0.747153\n",
            "2     3          0.720822          0.795875           0.739961\n",
            "3     4          0.726783          0.803698           0.754414\n",
            "4     5          0.744063          0.816501           0.774573\n"
          ]
        }
      ],
      "source": [
        "# Display the results  \n",
        "hasil = pd.DataFrame({\n",
        "    'Fold': list(range(1, len(f1_scores)+1)),\n",
        "    'F1 Score (macro)': f1_scores,\n",
        "    'Accuracy (macro)': acc_scores,\n",
        "    'Precision (macro)': prec_scores\n",
        "})\n",
        "\n",
        "print(\"\\n=== Evaluasi Model per Fold ===\")\n",
        "print(hasil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmR78n1ZwXXa",
        "outputId": "591e1635-8f53-4dd1-ea33-508ccfe3f382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Rata-rata Keseluruhan ===\n",
            "F1 Score (macro)     0.729277\n",
            "Accuracy (macro)     0.804608\n",
            "Precision (macro)    0.755182\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Display the overall average metrics  \n",
        "mean_metrics = hasil[['F1 Score (macro)', 'Accuracy (macro)', 'Precision (macro)']].mean()\n",
        "print(\"\\n=== Rata-rata Keseluruhan ===\")\n",
        "print(mean_metrics)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
